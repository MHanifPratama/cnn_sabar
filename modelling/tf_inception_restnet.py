# -*- coding: utf-8 -*-
"""tf  inception restnet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fYh9apgxlZC1sMIW41Ukzzegg0N3F14d
"""

!pip install keras_applications

!pip install tensorflow

import tensorflow as tf
from google.colab import drive, files
import numpy as np
import os
import tensorflow as tf
import shutil
import random
import cv2
from matplotlib import pyplot as plt
from google.colab import drive, files
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.optimizers import Adam

from keras.applications.inception_resnet_v2 import preprocess_input, InceptionResNetV2

from keras.models import Model
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
from keras_applications.imagenet_utils import _obtain_input_shape
from keras import backend as K
from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout
from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D
from tensorflow.python.keras.utils.data_utils import get_file

from tensorflow.keras.utils import get_source_inputs
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# Generate File Input Parh"""

drive.mount('cnn')

class Preprocessing:

    def load_data(input_directory,
                  train_directory,
                  input_img_size: int = 64,
                  mode_kelas="sparse"):

        CATEGORY = ['training', 'validation']
        data_generator = ImageDataGenerator(rescale=1/255,
                                  rotation_range=40,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='nearest')
        train_dataset = data_generator.flow_from_directory(train_directory, (input_img_size, input_img_size), class_mode=mode_kelas)

        output = []

        for category in CATEGORY:
            path = os.path.join(input_directory, category)
            print(path)
            images = []
            labels = []

            for folder in os.listdir(path):
                label = folder

                for file in os.listdir(os.path.join(path, folder)):
                    img_path = os.path.join(os.path.join(path, folder), file)
                    image = cv2.imread(img_path)
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    image = cv2.resize(image, (input_img_size, input_img_size))
                    images.append(image)
                    labels.append(label)

            images = np.array(images)
            labels = np.array(labels)
            output.append((images, labels))
            return output

    def datagen(input_directory, input_img_size: int, mode_kelas="sparse"):
        data_generator = ImageDataGenerator(rescale=1/255,
                                  rotation_range=40,
                                  width_shift_range=0.2,
                                  height_shift_range=0.2,
                                  shear_range=0.2,
                                  zoom_range=0.2,
                                  horizontal_flip=True,
                                  fill_mode='nearest')
        output = data_generator.flow_from_directory(input_directory, (input_img_size, input_img_size), class_mode=mode_kelas)
        return output

    def apply_preprocessing(dataset_folder,
                            output_folder,
                            val_split: float = 0.4,
                            apply_aug: bool = True):

        for folder in [output_folder, os.path.join(output_folder, 'training'), os.path.join(output_folder, 'validation')]:
            if not os.path.exists(folder):
                os.makedirs(folder)

    # Parameter untuk ukuran dataset validation
        validation_split = val_split
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # apply_augmentation
        def apply_augmentation(image):

            if random.random() < 0.5:
                # Flip gambar secara horizontal
                image = cv2.flip(image, 1)

            if random.random() < 0.5:
                # Menaikkan dan menurunkan kecerahan
                alpha = random.uniform(0.5, 1.5)
                image = cv2.multiply(image, np.array([alpha]))

            if random.random() < 0.5:
                # Menaikkan dan menurunkan kontras
                alpha = random.uniform(0.5, 1.5)
                grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                grey = cv2.cvtColor(grey, cv2.COLOR_GRAY2BGR)
                image = cv2.addWeighted(image, alpha, grey, 1 - alpha, 0)

            # if random.random() < 0.5:
            #     # Rotasi 90 derajat
            #     image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)

            return image

        for class_name in os.listdir(dataset_folder):
            class_folder = os.path.join(dataset_folder, class_name)

            training_class_folder = os.path.join(output_folder, 'training', class_name)
            validation_class_folder = os.path.join(output_folder, 'validation', class_name)
            for folder in [training_class_folder, validation_class_folder]:
                if not os.path.exists(folder):
                    os.makedirs(folder)

            image_files = os.listdir(class_folder)
            random.shuffle(image_files)
            num_validation_images = int(len(image_files) * validation_split)

            for i, image_name in enumerate(image_files) :
                image_path = os.path.join(class_folder, image_name)

                if i < num_validation_images:
                    output_image_path = os.path.join(validation_class_folder, image_name)
                else:
                    output_image_path = os.path.join(training_class_folder, image_name)

                image = cv2.imread(image_path)
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=16, minSize=(64, 64))

                if len(faces)>0:
                    for (x, y, w, h) in faces:
                        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), 0)
                        cropped = image[y:y + h, x:x + w]
                try:
                    cv2.imwrite(output_image_path, cropped)
                except:
                    continue

            if apply_aug == True:
                for i, image_name in enumerate(image_files) :
                    image_path = os.path.join(class_folder, image_name)
                    output_image_path = os.path.join(training_class_folder, image_name)
                    image = cv2.imread(image_path)
                    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=16, minSize=(64, 64))
                    if len(faces)>0:
                        for (x, y, w, h) in faces:
                            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 0), 0)
                            cropped = image[y:y + h, x:x + w]
                    try:
                        augmented = apply_augmentation(cropped)
                        cv2.imwrite(output_image_path, augmented)
                    except:
                        continue

#  Contoh penggunaan:
input_directory = "/content/cnn/MyDrive/RISET-CNN_Nathania/dataset/preprocessing"
output_directory = "/content/cnn/MyDrive/RISET-CNN_Nathania/dataset/hasil_Training"

# Preprocessing.apply_preprocessing(input_directory, output_directory)

"""## Model Inception Resnet v2

"""

data_path = os.path.join('/content/cnn/MyDrive/output')
train_path = os.path.join(data_path, 'training')
validation_path = os.path.join(data_path, 'validation')

train_data_gen = ImageDataGenerator(rescale=1/255)
validate_data_gen = ImageDataGenerator(rescale=1/255)

train_gen = train_data_gen.flow_from_directory(train_path, (128,128),batch_size=3)
validate_gen = validate_data_gen.flow_from_directory(validation_path, (128,128), batch_size=3)

model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3))
model = Model(inputs=model.input, outputs=model.layers[-5].output)
base_out = model.output
base_out = Flatten()(base_out)
base_out = Dense(train_gen.num_classes, activation='softmax')(base_out)
model = Model(inputs=model.input, outputs=base_out)
model.summary()

# Ambil satu batch data dari generator aliran data pelatihan
batch_images, batch_labels = next(train_gen)

# Mencetak contoh data dan kelasnya
for i in range(len(batch_images)):
    image = batch_images[i]
    label = batch_labels[i]

    # Menampilkan gambar
    plt.imshow(image)
    plt.title(f"Class: {np.argmax(label)}")  # Label kelas langsung digunakan sebagai indeks
    plt.show()

model.compile(optimizer=Adam(learning_rate=0.0001), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])

saveBestInceptResNet= tf.keras.callbacks.ModelCheckpoint('InceptResNetV2.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)

history = model.fit(train_gen,
                    epochs=10,
                    validation_data=validate_gen,
                    callbacks=[saveBestInceptResNet]
                    )

plt.plot(history.history['accuracy'])
plt.plot(history.history['loss'])
plt.title('training accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper left')
plt.show()

plt.plot(history.history['val_accuracy'])
plt.plot(history.history['val_loss'])
plt.title('validation accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['accuracy', 'loss'], loc='upper left')
plt.show()

best_model = tf.keras.models.load_model('InceptResNetV2.h5')

"""## Test"""

test_dir = os.path.join(data_path, 'testing')

for image in os.listdir(test_dir):
  image_path = os.path.join(test_dir, image)
  image = load_img(image_path, target_size=(128,128))
  plt.imshow(image)
  plt.show()

  x = img_to_array(image)
  x = np.expand_dims(x, axis=0)
  img = np.vstack([x])

  pred = best_model.predict(img)

  predicted_class = np.argmax(pred, axis=1)
  labels = (train_gen.class_indices)
  labels = dict((v,k) for k,v in labels.items())

  predictions = [labels[k] for k in predicted_class]
  print(predictions)

