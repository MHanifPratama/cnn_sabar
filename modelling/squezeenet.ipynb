{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z2eQX2So8yB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fire_module(inputs,s1x1,e1x1,e3x3,name=\"fire\"):\n",
        "    w_init = tf.truncated_normal_initializer(mean=0.0, stddev=(1.0/int(inputs.shape[2])))\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        #squeeze layer\n",
        "        squeeze_out = tf.layers.conv2d(inputs,filters=s1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
        "        relu_sq = tf.nn.relu(squeeze_out)\n",
        "\n",
        "        #expand layer\n",
        "        k1_exp = tf.layers.conv2d(relu_sq,filters=e1x1,kernel_size=1,strides=1,padding=\"VALID\",kernel_initializer=w_init)\n",
        "        k1_relu = tf.nn.relu(k1_exp)\n",
        "        k3_exp = tf.layers.conv2d(relu_sq,filters=e3x3,kernel_size=3,strides=1,padding=\"SAME\",kernel_initializer=w_init)\n",
        "        k3_relu = tf.nn.relu(k3_exp)\n",
        "\n",
        "        return tf.concat([k1_relu,k3_relu],axis=3)\n"
      ],
      "metadata": {
        "id": "MsQ4S3GJpWDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Layer buat konvolusinya\n",
        "\"\"\"\n",
        "def general_conv(inputs,filters,kernel,stride=1,padding='VALID',name=\"conv\",relu = True,weight=\"Xavier\"):\n",
        "    if str(weight) == str(\"Xavier\"):\n",
        "        w_init = tf.truncated_normal_initializer(mean=0.0,stddev=(1.0/int(inputs.shape[2])))\n",
        "    else:\n",
        "        w_init = tf.truncated_normal_initializer(mean=0.0,stddev=0.01)\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "        conv = tf.layers.conv2d(inputs,filters,kernel,stride,padding,kernel_initializer=w_init)\n",
        "        if relu == True:\n",
        "                conv = tf.nn.relu(conv)\n",
        "        return conv\n",
        "\n",
        "\"\"\"\n",
        "SqueezeNet Class Definition\n",
        "\"\"\"\n",
        "class SqueezeNet:\n",
        "\n",
        "    def __init__(self,input_shape,out_classes,lr_rate,train):\n",
        "        self.lr_rate = tf.placeholder(tf.float32,name=\"lr_rate\")\n",
        "        self.out_classes = out_classes\n",
        "        self.inputs = tf.placeholder(tf.float32,shape=(None,input_shape[0],input_shape[1],input_shape[2]))\n",
        "        self.labels = tf.placeholder(tf.float32,shape=(None,self.out_classes))\n",
        "        self.loss_v0,self.loss_v0_res,self.loss_v1 = self.model_loss(self.inputs,self.labels,train)\n",
        "        self.v0_opt,self.v0_res_opt,self.v1_opt = self.model_opti(self.loss_v0,self.loss_v0_res,self.loss_v1,self.lr_rate)\n",
        "\n",
        "    #Model Definition of SqueezeNet V0\n",
        "    def model_arc_v0(self,inputs,train,reuse=False):\n",
        "\n",
        "        with tf.variable_scope(\"squeezenet_v0\",reuse=reuse):\n",
        "            conv1 = general_conv(inputs,filters=96,kernel=7,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
        "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
        "\n",
        "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
        "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
        "            fire4 = fire_module(fire3,32,128,128,name=\"fire4\")\n",
        "\n",
        "            pool2 = tf.layers.max_pooling2d(fire4,pool_size=3,strides=2,name=\"pool2\")\n",
        "\n",
        "            fire5 = fire_module(pool2,32,128,128,name=\"fire5\")\n",
        "            fire6 = fire_module(fire5,48,192,192,name=\"fire6\")\n",
        "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
        "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
        "\n",
        "            pool3 = tf.layers.max_pooling2d(fire8,pool_size=3,strides=2,name=\"pool3\")\n",
        "\n",
        "            fire9 = fire_module(pool3,64,256,256,name=\"fire9\")\n",
        "            drop = tf.layers.dropout(fire9,rate=0.5,training=train)\n",
        "\n",
        "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
        "\n",
        "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
        "            pool_shape = tf.shape(avg_pool)\n",
        "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
        "\n",
        "            return logits\n",
        "\n",
        "    #Model Definiton of SqueezeNet V1\n",
        "    def model_arc_v1(self,inputs,train,reuse=False):\n",
        "\n",
        "        with tf.variable_scope(\"squeezenet_v1\",reuse=reuse):\n",
        "            conv1 = general_conv(inputs,filters=64,kernel=3,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
        "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
        "\n",
        "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
        "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
        "\n",
        "            pool2 = tf.layers.max_pooling2d(fire3,pool_size=3,strides=2,name=\"pool2\")\n",
        "\n",
        "            fire4 = fire_module(pool2,32,128,128,name=\"fire4\")\n",
        "            fire5 = fire_module(fire4,32,128,128,name=\"fire5\")\n",
        "\n",
        "            pool3 = tf.layers.max_pooling2d(fire5,pool_size=3,strides=2,name=\"pool3\")\n",
        "\n",
        "            fire6 = fire_module(pool3,48,192,192,name=\"fire6\")\n",
        "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
        "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
        "            fire9 = fire_module(fire8,64,256,256,name=\"fire9\")\n",
        "            drop = tf.layers.dropout(fire9,rate=0.5,training=train)\n",
        "\n",
        "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
        "\n",
        "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
        "\n",
        "            pool_shape = tf.shape(avg_pool)\n",
        "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
        "\n",
        "            return logits\n",
        "\n",
        "\n",
        "    #Model Definition of SqueezeNet V0 Residual\n",
        "    def model_arc_v0_res(self,inputs,train,reuse=False):\n",
        "\n",
        "        with tf.variable_scope(\"squeezenet_v0_res\",reuse=reuse):\n",
        "            conv1 = general_conv(inputs,filters=96,kernel=7,stride=2,padding=\"SAME\",name=\"conv1\",relu=True,weight=\"Xavier\")\n",
        "            pool1 = tf.layers.max_pooling2d(conv1,pool_size=3,strides=2,name=\"pool1\")\n",
        "\n",
        "            fire2 = fire_module(pool1,16,64,64,name=\"fire2\")\n",
        "            fire3 = fire_module(fire2,16,64,64,name=\"fire3\")\n",
        "\n",
        "            bypass_23 = tf.add(fire2,fire3,name=\"bypass_23\")\n",
        "\n",
        "            fire4 = fire_module(bypass_23,32,128,128,name=\"fire4\")\n",
        "            pool2 = tf.layers.max_pooling2d(fire4,pool_size=3,strides=2,name=\"pool2\")\n",
        "            fire5 = fire_module(pool2,32,128,128,name=\"fire5\")\n",
        "\n",
        "            bypass_45 = tf.add(pool2,fire5,name=\"bypass_45\")\n",
        "\n",
        "            fire6 = fire_module(bypass_45,48,192,192,name=\"fire6\")\n",
        "            fire7 = fire_module(fire6,48,192,192,name=\"fire7\")\n",
        "            fire8 = fire_module(fire7,64,256,256,name=\"fire8\")\n",
        "\n",
        "            pool3 = tf.layers.max_pooling2d(fire8,pool_size=3,strides=2,name=\"pool3\")\n",
        "\n",
        "            fire9 = fire_module(pool3,64,256,256,name=\"fire9\")\n",
        "\n",
        "            bypass_89 = tf.add(pool3,fire9,name=\"bypass_89\")\n",
        "\n",
        "            drop = tf.layers.dropout(bypass_89,rate=0.5,training=train)\n",
        "\n",
        "            conv10 = general_conv(drop,filters=200,kernel=1,stride=1,padding=\"SAME\",name=\"conv10\",relu=True,weight=\"Gaussian\")\n",
        "\n",
        "            avg_pool = tf.layers.average_pooling2d(conv10,pool_size=13,strides=1,name=\"pool_end\")\n",
        "\n",
        "            pool_shape = tf.shape(avg_pool)\n",
        "            logits = tf.reshape(avg_pool,shape=(pool_shape[0],pool_shape[3]))\n",
        "\n",
        "            return logits\n",
        "\n",
        "\n",
        "    #Function to calculate loss\n",
        "    def model_loss(self,inputs,label,train):\n",
        "        logits_v0 = self.model_arc_v0(inputs,train)\n",
        "        logits_v0_res = self.model_arc_v0_res(inputs,train)\n",
        "        logits_v1 = self.model_arc_v1(inputs,train)\n",
        "\n",
        "        loss_v0 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v0,labels=label))\n",
        "        loss_v0_res = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v0_res,labels=label))\n",
        "        loss_v1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_v1,labels=label))\n",
        "\n",
        "        return loss_v0,loss_v0_res,loss_v1\n",
        "\n",
        "    #Function to calculate prediction form models\n",
        "    def model_prediction(self,inputs,train):\n",
        "        logits_v0 = self.model_arc_v0(inputs,train,True)\n",
        "        logits_v0_res = self.model_arc_v0_res(inputs,train,True)\n",
        "        logits_v1 = self.model_arc_v1(inputs,train,True)\n",
        "\n",
        "        predict_v0 = tf.nn.softmax(logits_v0)\n",
        "        predict_v0_res = tf.nn.softmax(logits_v0_res)\n",
        "        predict_v1 = tf.nn.softmax(logits_v1)\n",
        "\n",
        "        return predict_v0,predict_v0_res,predict_v1\n",
        "\n",
        "    #Function to optimize the models.\n",
        "    def model_opti(self,loss_v0,loss_v0_res,loss_v1,lr_rate):\n",
        "\n",
        "        train_vars = tf.trainable_variables()\n",
        "        v0_vars = [var for var in train_vars if var.name.startswith('squeezenet_v0')]\n",
        "        v0_res_vars = [var for var in train_vars if var.name.startswith('squeezenet_v0_res')]\n",
        "        v1_vars = [var for var in train_vars if var.name.startswith('squeezenet_v1')]\n",
        "\n",
        "        #Using Adam Optimizer\n",
        "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "            v0_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v0,var_list=v0_vars)\n",
        "            v0_res_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v0_res,var_list=v0_res_vars)\n",
        "            v1_train_opt = tf.train.AdamOptimizer(lr_rate).minimize(loss_v1,var_list=v1_vars)\n",
        "\n",
        "        return v0_train_opt, v0_res_train_opt, v1_train_opt\n",
        "\n",
        "\n",
        "# tambahin dense layer\n"
      ],
      "metadata": {
        "id": "Rc8ZYbNWpWjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training function"
      ],
      "metadata": {
        "id": "1nTqPq2Nprvd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8qQo7Y9porm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}