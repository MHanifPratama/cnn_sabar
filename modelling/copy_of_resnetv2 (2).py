# -*- coding: utf-8 -*-
"""Copy of resnetv2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EMm5k_eZuEZ760tC2gg5Vv2W97JdZO-S
"""

import os
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import shutil
import random
from google.colab import drive, files
import numpy as np
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import torchvision
from PIL import Image
from torchvision import transforms
from collections import *
from PIL import Image
import torchvision.utils as vutils
from torch import optim
from torchvision import datasets, transforms, models

drive.mount('cnn')

base_path = os.path.join('/content/cnn/MyDrive/RISET-CNN_Nathania/dataset/hasil_Training')
train_path = os.path.join(base_path, 'training')
validation_path = os.path.join(base_path, 'validation')

import os
from PIL import Image
import matplotlib.image as mpimg

# Check if the directory exists
if not os.path.exists(train_path):
    print(f"The directory '{train_path}' does not exist.")
    exit()
# Get a list of all files in the directory
class_names = os.listdir(train_path)

len(class_names) #get a list for class name for each of image

train_transforms = transforms.Compose([torchvision.transforms.Resize((299, 299)),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.5, 0.5, 0.5],
                                                            [0.2, 0.2, 0.2])])

test_transforms = transforms.Compose([torchvision.transforms.Resize((299, 299)),
                                      transforms.CenterCrop(224),
                                      transforms.ToTensor(),
                                      transforms.Normalize([0.5, 0.5, 0.5],
                                                           [0.2, 0.2, 0.2])])

train_data = datasets.ImageFolder(base_path + '/training', transform=train_transforms)
test_data = datasets.ImageFolder(base_path + '/validation', transform=test_transforms)


train_loader = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=2, shuffle=False)

train_loader

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

device

data_iter = next(iter(train_loader))

plt.figure(figsize=(8,8))
plt.axis("off")
plt.title("Sample Images")
plt.imshow(np.transpose(vutils.make_grid(data_iter[0].to(device)[:64], padding=2, normalize=True).cpu(),(1, 2, 0)))

import torch.nn as nn

class InceptionResnetV2_Simple(nn.Module):

    def __init__(self, num_classes):
        super(InceptionResnetV2_Simple, self).__init__()
        # Stem
        self.conv_1a = BasicConv2(3, 32, kernel_size=3, stride=2)
        self.conv_2a = BasicConv2(32, 32, kernel_size=3, stride=1)
        self.conv_2b = BasicConv2(32, 64, kernel_size=3, stride=1, padding=1)
        self.maxpool_3a = nn.MaxPool2d(3, stride=2)
        self.conv_3b = BasicConv2(64, 80, kernel_size=1, stride=1)
        self.conv_3c = BasicConv2(80, 192, kernel_size=3, stride=1)
        self.maxpool_4a = nn.MaxPool2d(3, stride=2)

        self.branch_0 = BasicConv2(192, 96, kernel_size=1, stride=1)
        self.branch_1 = nn.Sequential(
            BasicConv2(192, 48, kernel_size=1, stride=1),
            BasicConv2(48, 64, kernel_size=5, stride=1, padding=2)
        )
        self.branch_2 = nn.Sequential(
            BasicConv2(192, 64, kernel_size=1, stride=1),
            BasicConv2(64, 96, kernel_size=3, stride=1, padding=1),
            BasicConv2(96, 96, kernel_size=3, stride=1, padding=1)
        )
        self.branch_3 = nn.Sequential(
            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),
            BasicConv2(192, 64, kernel_size=1, stride=1)
        )

        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))
        self.liner = nn.Linear(320, num_classes)

    def forward(self, x):
        # Stem
        x = self.conv_1a(x)
        x = self.conv_2a(x)
        x = self.conv_2b(x)
        x = self.maxpool_3a(x)
        x = self.conv_3b(x)
        x = self.conv_3c(x)
        x = self.maxpool_4a(x)
        x0 = self.branch_0(x)
        x1 = self.branch_1(x)
        x2 = self.branch_2(x)
        x3 = self.branch_3(x)
        x = torch.cat((x0, x1, x2, x3), dim=1)

        x = self.global_average_pooling(x)
        x = x.view(x.size(0), -1)
        x = self.liner(x)
        return x

class BasicConv2(nn.Module):
    def __init__(self, in_size, out_size, kernel_size, stride, padding=0):
        super(BasicConv2, self).__init__()
        self.conv = nn.Conv2d(in_size, out_size, kernel_size=kernel_size,
                              stride=stride, padding=padding, bias=False)
        self.batch_norm = nn.BatchNorm2d(out_size)
        self.relu = nn.ReLU(inplace=False)

    def forward(self, x):
        x = self.conv(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        return x


model = InceptionResnetV2_Simple(63).to(device)
model

def train(model, batch, optimizer):
    model.train()
    optimizer.zero_grad()
    inputs, labels = batch
    inputs = inputs.to(device)
    labels = labels.to(device)
    outputs = model(inputs)
    l = criterion(outputs, labels)
    l.backward()
    optimizer.step()
    return l

def evaluate(model, batch, optimizer):
    model.eval()
    inputs, labels = batch
    inputs = inputs.to(device)
    labels = labels.to(device)
    outputs = model(inputs)
    a = accuracy(outputs, labels)
    l = criterion(outputs, labels)
    return a, l

def accuracy(outputs, labels):
    _, preds = torch.max(F.log_softmax(outputs, dim=1), dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

def predicts(outputs):
    _, preds = torch.max(F.log_softmax(outputs, dim=1), dim=1)
    return preds

criterion = torch.nn.CrossEntropyLoss()

LEARNING_RATE = 0.0001
optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=False)
val_loader = torch.utils.data.DataLoader(test_data, batch_size=32)

# Check the number of classes in your   # Make sure this matches the number of classes in your dataset

# ...

# Verify class labels in your datasets
print("Training Data Classes:", train_data.classes)
print("Validation Data Classes:", test_data.classes)

# Print some labels from the training and validation datasets
for batch in train_loader:
    _, labels = batch
    print("Training Batch Labels:", labels)
    break

for batch in val_loader:
    _, labels = batch
    print("Validation Batch Labels:", labels)
    break

# Import callback yang diperlukan
import os
import torch
import torch.nn as nn
import torchvision
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms, models
from torch import optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import torchvision.utils as vutils


checkpoint_dir = "checkpoints"
os.makedirs(checkpoint_dir, exist_ok=True)

# Fungsi untuk menyimpan model
def save_checkpoint(epoch, model, optimizer, filename):
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': criterion,
    }
    torch.save(checkpoint, filename)

# Latih model Anda dengan menyimpan checkpoint
epochs = 50  # Ganti dengan jumlah epochnya
for epoch in range(epochs):
    # Kode pelatihan Anda di sini

    # Setelah setiap epoch, simpan checkpoint
    checkpoint_filename = os.path.join(checkpoint_dir, f'checkpoint_epoch{epoch}.pth')
    save_checkpoint(epoch, model, optimizer, checkpoint_filename)

# ...

# Train the model with the callback
for epoch in range(60):
    print('Epoch:', epoch + 1)
    c = 0
    for batch in train_loader:
        l = train(model, batch, optimizer)
        c += len(batch[0])
        print("[%d/%d] Loss: %.2f" % (c, len(train_data), l.item()))

    for batch in train_loader:
        a, l = evaluate(model, batch, optimizer)
        print("Train Loss: %.2f, Train Accuracy: %.2f" % (l.item(), a.item()))
        break

    acc = 0
    loo = 0
    d = 0
    for batch in val_loader:
        a, l = evaluate(model, batch, optimizer)
        acc += a.item()
        loo += l.item()
        d += 1
    print("Val Loss: %.2f, Val Accuracy: %.2f" % (loo / d, acc / d))

FILE = "/content/checkpoints/checkpoint_epoch49.pth"
torch.save(model.state_dict(), FILE)


loaded_model = InceptionResnetV2_Simple(63)
loaded_model.load_state_dict(torch.load(FILE))
loaded_model.eval()

for param in loaded_model.parameters():
  print(param)

import os
import torch
from torch.optim import Adam
from torch.nn import CrossEntropyLoss
from torchvision import transforms, datasets, models
from torch.utils.data import DataLoader

from torch.optim.lr_scheduler import StepLR
from torchvision import transforms, datasets
from torch.utils.data import DataLoader
import torch.nn.functional as F
from sklearn.metrics import accuracy_score

from torch.autograd import Variable

# Import callback yang diperlukan
from torch.utils.tensorboard import SummaryWriter
from datetime import datetime

# Inisialisasi writer tensorboard
current_time = datetime.now().strftime("%Y%m%d-%H%M%S")
writer = SummaryWriter(os.path.join('logs', current_time))

# Definisikan ModelCheckpoint callback
class ModelCheckpoint:
    def __init__(self, checkpoint_dir, monitor='val_loss', mode='min'):
        self.checkpoint_dir = checkpoint_dir
        self.monitor = monitor
        self.mode = mode
        self.best_value = None

    def __call__(self, epoch, model, optimizer, loss):
        if self.monitor == 'val_loss':
            value = loss
        else:
            # Anda dapat menambahkan kode untuk memantau metrik lain jika diperlukan
            pass

        if self.best_value is None or (self.mode == 'min' and value < self.best_value) or (self.mode == 'max' and value > self.best_value):
            self.best_value = value
            self.save_checkpoint(epoch, model, optimizer)

    def save_checkpoint(self, epoch, model, optimizer):
        checkpoint_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch{epoch}.pth')
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
        }, checkpoint_path)

def test(model, testloader):
    """
    Function to test the model
    """
    # set model to evaluation mode
    model.eval()
    print('Testing')
    valid_running_correct = 0
    counter = 0
    with torch.no_grad():
        for i, data in tqdm(enumerate(testloader), total=len(testloader)):
            counter += 1

            image, labels = data
            image = image.to(device)
            labels = labels.to(device)
            # forward pass
            outputs = model(image)
            # calculate the accuracy
            _, preds = torch.max(outputs.data, 1)
            valid_running_correct += (preds == labels).sum().item()

    # loss and accuracy for the complete epoch
    final_acc = 100. * (valid_running_correct / len(testloader.dataset))
    return final_acc

def create_data_loaders(dataset_train, dataset_valid, dataset_test):
    """
    Function to build the data loaders.
    Parameters:
    :param dataset_train: The training dataset.
    :param dataset_valid: The validation dataset.
    :param dataset_test: The test dataset.
    """
    train_loader = DataLoader(
        dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS
    )
    valid_loader = DataLoader(
        dataset_valid, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS
    )
    test_loader = DataLoader(
        dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS
    )
    return train_loader, valid_loader, test_loader

train_loader, valid_loader, _ = create_data_loaders(
    train_data, test_data, test_dataset
)

"""## Salah"""

# Initialize the ModelCheckpoint callback
checkpoint_dir = "checkpoints"
os.makedirs(checkpoint_dir, exist_ok=True)
checkpoint_callback = ModelCheckpoint(checkpoint_dir, monitor='val_loss', mode='min')

# Train the model with the callback
epochs = 50  # Ganti dengan jumlah epochnya
for epoch in range(50):
    print('Epoch:', epoch + 1)
    c = 0
    for batch in train_loader:
        l = train(model, batch, optimizer)
        c += len(batch[0])
        print("[%d/%d] Loss: %.2f" % (c, len(train_data), l.item()))

    for batch in train_loader:
        a, l = evaluate(model, batch, optimizer)
        print("Train Loss: %.2f, Train Accuracy: %.2f" % (l.item(), a.item()))
        break

    acc = 0
    loo = 0
    d = 0
    for batch in val_loader:
        a, l = evaluate(model, batch, optimizer)
        acc += a.item()
        loo += l.item()
        d += 1
    print("Val Loss: %.2f, Val Accuracy: %.2f" % (loo / d, acc / d))

    # Save the model using the ModelCheckpoint callback
    checkpoint_callback(epoch, model, optimizer, loo / d)  # Trigger the callback

# ...

# After training, you can load the best model like this
best_checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch{checkpoint_callback.best_epoch}.pth')
best_model_checkpoint = torch.load(best_checkpoint_path)
model.load_state_dict(best_model_checkpoint['model_state_dict'])
model.eval()

# ...

# Continue with further evaluation or inference



for epoch in range(50):
    print('Epoch:', epoch + 1)
    c = 0
    for batch in train_loader:
        l = train(model, batch, optimizer)
        c += len(batch[0])
        print("[%d/%d] Loss: %.2f" % (c, len(train_data), l.item()))

    for batch in train_loader:
        a, l = evaluate(model, batch, optimizer)
        print("Train Loss: %.2f, Train Accuracy: %.2f" % (l.item(), a.item()))
        break

    acc = 0
    loo = 0
    d = 0
    for batch in val_loader:
        a, l = evaluate(model, batch, optimizer)
        acc += a.item()
        loo += l.item()
        d += 1
    print("Val Loss: %.2f, Val Accuracy: %.2f" % (loo / d, acc / d))



